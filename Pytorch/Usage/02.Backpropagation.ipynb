{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02.Backpropagation.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNhLzyjyA8AGMUu7CqyI4rS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"krAHkYUgpMSZ","executionInfo":{"status":"ok","timestamp":1624332084366,"user_tz":-540,"elapsed":887,"user":{"displayName":"최성욱","photoUrl":"","userId":"06654770949516275646"}},"outputId":"b1b1a55d-9f6f-4d83-e934-f45f66aa3928"},"source":["import torch\n","\n","# 자동 미분 준비\n","x = torch.ones((2,2), requires_grad=True) # requires_grad=True: 해당 텐서를 기준으로 모든 연산들을 추적(x를 기준으로 미분 가능)\n","y = x + 1\n","z = 2*y**2\n","result = z.mean()\n","\n","print(f\"x:\\n{x}\")\n","print(f\"y:\\n{y}\")\n","print(f\"z:\\n{z}\")\n","print('result:\\n', result, '\\n') # grad_fn=..은 추적이 잘되고 있다는 의미\n","\n","# Backpropagation\n","result.backward() # result 기준으로 Backpropagation을 진행\n","print(f\"x.grad:\\n{x.grad}\") # x.grad: backward()가 선언된 기준으로 미분을 계산(d(result)/dx)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["x:\n","tensor([[1., 1.],\n","        [1., 1.]], requires_grad=True)\n","y:\n","tensor([[2., 2.],\n","        [2., 2.]], grad_fn=<AddBackward0>)\n","z:\n","tensor([[8., 8.],\n","        [8., 8.]], grad_fn=<MulBackward0>)\n","result:\n"," tensor(8., grad_fn=<MeanBackward0>) \n","\n","x.grad:\n","tensor([[2., 2.],\n","        [2., 2.]])\n"],"name":"stdout"}]}]}